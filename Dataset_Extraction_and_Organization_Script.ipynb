{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oxj_rNjiFYsR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from Bio import SeqIO\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "import pandas as pd\n",
        "\n",
        "class BenchmarkDatasetExtractor:\n",
        "    def __init__(self, fasta_file):\n",
        "        self.fasta_file = fasta_file\n",
        "        self.sequences = list(SeqIO.parse(fasta_file, \"fasta\"))\n",
        "\n",
        "    def analyze_dataset(self):\n",
        "        \"\"\"Analyze the dataset characteristics\"\"\"\n",
        "        stats = {\n",
        "            'total_sequences': len(self.sequences),\n",
        "            'sequence_lengths': [len(seq.seq) for seq in self.sequences],\n",
        "            'organisms': set(),\n",
        "            'protein_families': set()\n",
        "        }\n",
        "\n",
        "        for seq in self.sequences:\n",
        "            # Extract organism information from description\n",
        "            desc = seq.description.lower()\n",
        "            if 'pseudomonas' in desc:\n",
        "                stats['organisms'].add('Pseudomonas')\n",
        "            elif 'keratin' in desc:\n",
        "                stats['protein_families'].add('Keratin')\n",
        "            # Add more classification logic as needed\n",
        "\n",
        "        stats['avg_length'] = sum(stats['sequence_lengths']) / len(stats['sequence_lengths'])\n",
        "        stats['min_length'] = min(stats['sequence_lengths'])\n",
        "        stats['max_length'] = max(stats['sequence_lengths'])\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def create_benchmark_subsets(self):\n",
        "        \"\"\"Create different benchmark subsets\"\"\"\n",
        "\n",
        "        # 1. Najna18-like subset (18 sequences)\n",
        "        najna18 = random.sample(self.sequences, min(18, len(self.sequences)))\n",
        "\n",
        "        # 2. Enzymes30-like subset (30 sequences)\n",
        "        enzymes30 = random.sample(self.sequences, min(30, len(self.sequences)))\n",
        "\n",
        "        # 3. Keratin100-like subset (all keratin sequences)\n",
        "        keratin100 = [seq for seq in self.sequences if 'keratin' in seq.description.lower()]\n",
        "        if len(keratin100) > 100:\n",
        "            keratin100 = random.sample(keratin100, 100)\n",
        "\n",
        "        # 4. BAliBASE-style subsets (different difficulties)\n",
        "        easy_subset = [seq for seq in self.sequences if 100 <= len(seq.seq) <= 200][:20]\n",
        "        medium_subset = [seq for seq in self.sequences if 200 < len(seq.seq) <= 400][:20]\n",
        "        hard_subset = [seq for seq in self.sequences if len(seq.seq) > 400][:20]\n",
        "\n",
        "        return {\n",
        "            'Najna18': najna18,\n",
        "            'Enzymes30': enzymes30,\n",
        "            'Keratin100': keratin100,\n",
        "            'BAliBASE_Easy': easy_subset,\n",
        "            'BAliBASE_Medium': medium_subset,\n",
        "            'BAliBASE_Hard': hard_subset\n",
        "        }\n",
        "\n",
        "    def save_benchmark_datasets(self, output_dir=\"benchmark_datasets\"):\n",
        "        \"\"\"Save all benchmark datasets to files\"\"\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        stats = self.analyze_dataset()\n",
        "        subsets = self.create_benchmark_subsets()\n",
        "\n",
        "        # Save dataset statistics\n",
        "        stats_df = pd.DataFrame([stats])\n",
        "        stats_df.to_csv(f\"{output_dir}/dataset_statistics.csv\", index=False)\n",
        "\n",
        "        # Save individual benchmark files\n",
        "        for subset_name, sequences in subsets.items():\n",
        "            if sequences:  # Only save non-empty subsets\n",
        "                filename = f\"{output_dir}/{subset_name}.fasta\"\n",
        "                with open(filename, \"w\") as f:\n",
        "                    SeqIO.write(sequences, f, \"fasta\")\n",
        "                print(f\"Saved {subset_name}: {len(sequences)} sequences\")\n",
        "\n",
        "        # Save the full dataset\n",
        "        full_filename = f\"{output_dir}/Full_Dataset.fasta\"\n",
        "        with open(full_filename, \"w\") as f:\n",
        "            SeqIO.write(self.sequences, f, \"fasta\")\n",
        "\n",
        "        print(f\"\\nDataset Analysis:\")\n",
        "        print(f\"Total sequences: {stats['total_sequences']}\")\n",
        "        print(f\"Average length: {stats['avg_length']:.2f}\")\n",
        "        print(f\"Length range: {stats['min_length']} - {stats['max_length']}\")\n",
        "        print(f\"Organisms: {list(stats['organisms'])}\")\n",
        "\n",
        "        return subsets\n",
        "\n",
        "# Usage\n",
        "if __name__ == \"__main__\":\n",
        "    extractor = BenchmarkDatasetExtractor(\"keratin_sequences.fasta\")\n",
        "    datasets = extractor.save_benchmark_datasets()"
      ]
    }
  ]
}